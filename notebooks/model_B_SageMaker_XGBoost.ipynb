{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16c1df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, numpy as np, pandas as pd, boto3, sagemaker\n",
    "from sagemaker import Session\n",
    "from sagemaker.s3 import S3Uploader, S3Downloader\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "sess: Session = sagemaker.Session()\n",
    "region = boto3.Session().region_name or \"us-west-2\"\n",
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()\n",
    "\n",
    "bucket = sess.default_bucket()  # or set your own bucket name\n",
    "prefix = \"gunshot-mvp/modelB-xgb\"  # S3 folder prefix for this project\n",
    "\n",
    "print(\"Region:\", region)\n",
    "print(\"Role:\", role)\n",
    "print(\"Bucket:\", bucket)\n",
    "print(\"S3 prefix:\", prefix)\n",
    "\n",
    "LOCAL_INPUT = r\"C:\\Hackathon\\gunshot\\modelB_predictors.csv\"   # change if your file is elsewhere\n",
    "\n",
    "EVENT_START_S = 25202.5\n",
    "EVENT_END_S   = 25227.5\n",
    "\n",
    "TRAIN_FRAC = 0.70   # first 70% of time\n",
    "VAL_FRAC   = 0.15   # next 15% (tune cutoff here)\n",
    "\n",
    "PERSIST_TICKS = 2   # e.g., 2 ticks × 2.5s ≈ 5 seconds\n",
    "\n",
    "CUTOFF_GRID = np.linspace(0.50, 0.95, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8118f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your predictors (2 features + time)\n",
    "df = pd.read_csv(LOCAL_INPUT)\n",
    "assert {\"t\",\"outward_fraction\",\"mean_outward_speed_mps\"}.issubset(df.columns)\n",
    "\n",
    "# Label: 1 for evac-like frames inside the event window, else 0\n",
    "df[\"label\"] = ((df[\"t\"] >= EVENT_START_S) & (df[\"t\"] <= EVENT_END_S)).astype(int)\n",
    "\n",
    "# Sort by time and check cadence\n",
    "df = df.sort_values(\"t\").reset_index(drop=True)\n",
    "tick_mode = df[\"t\"].diff().dropna().mode()\n",
    "tick = float(tick_mode.iloc[0]) if len(tick_mode) else 2.5\n",
    "print(f\"Detected tick ~ {tick:.2f} s\")\n",
    "\n",
    "# Time-based split borders\n",
    "unique_t = df[\"t\"].unique()\n",
    "nT = len(unique_t)\n",
    "t_train_end = unique_t[int(nT * TRAIN_FRAC) - 1]\n",
    "t_val_end   = unique_t[int(nT * (TRAIN_FRAC + VAL_FRAC)) - 1]\n",
    "\n",
    "is_train = df[\"t\"] <= t_train_end\n",
    "is_val   = (df[\"t\"] > t_train_end) & (df[\"t\"] <= t_val_end)\n",
    "is_test  = df[\"t\"] > t_val_end\n",
    "\n",
    "print(\"Time split:\")\n",
    "print(f\"  Train: t <= {t_train_end}\")\n",
    "print(f\"  Val:   {t_train_end} < t <= {t_val_end}\")\n",
    "print(f\"  Test:  t > {t_val_end}\")\n",
    "\n",
    "# Keep only the two features for XGBoost\n",
    "FEATS = [\"outward_fraction\", \"mean_outward_speed_mps\"]\n",
    "\n",
    "# Build CSVs for SageMaker XGBoost (label FIRST, no header) for TRAIN/VAL\n",
    "train_csv = pd.concat([df.loc[is_train, \"label\"], df.loc[is_train, FEATS]], axis=1)\n",
    "val_csv   = pd.concat([df.loc[is_val,   \"label\"], df.loc[is_val,   FEATS]], axis=1)\n",
    "\n",
    "train_path_local = \"train.csv\"\n",
    "val_path_local   = \"validation.csv\"\n",
    "train_csv.to_csv(train_path_local, index=False, header=False)\n",
    "val_csv.to_csv(val_path_local,     index=False, header=False)\n",
    "\n",
    "# For inference, features ONLY (no label, no header) for VAL and TEST\n",
    "val_feats_local  = \"val_features.csv\"\n",
    "test_feats_local = \"test_features.csv\"\n",
    "df.loc[is_val,  FEATS].to_csv(val_feats_local,  index=False, header=False)\n",
    "df.loc[is_test, FEATS].to_csv(test_feats_local, index=False, header=False)\n",
    "\n",
    "# Keep time and labels locally to rejoin later\n",
    "val_meta  = df.loc[is_val,  [\"t\",\"label\"]].reset_index(drop=True)\n",
    "test_meta = df.loc[is_test, [\"t\",\"label\"]].reset_index(drop=True)\n",
    "\n",
    "print(\"Local files ready:\",\n",
    "      train_path_local, val_path_local, val_feats_local, test_feats_local)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb54326",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s3_uri = S3Uploader.upload(train_path_local,  f\"s3://{bucket}/{prefix}/train\")\n",
    "val_s3_uri   = S3Uploader.upload(val_path_local,    f\"s3://{bucket}/{prefix}/validation\")\n",
    "valX_s3_uri  = S3Uploader.upload(val_feats_local,   f\"s3://{bucket}/{prefix}/inference/val\")\n",
    "testX_s3_uri = S3Uploader.upload(test_feats_local,  f\"s3://{bucket}/{prefix}/inference/test\")\n",
    "\n",
    "print(\"S3 URIs:\")\n",
    "print(\"  train :\", train_s3_uri)\n",
    "print(\"  val   :\", val_s3_uri)\n",
    "print(\"  val X :\", valX_s3_uri)\n",
    "print(\"  test X:\", testX_s3_uri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b04ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output folders (S3) for batch predictions\n",
    "batch_out_val  = f\"s3://{bucket}/{prefix}/batch-out/val\"\n",
    "batch_out_test = f\"s3://{bucket}/{prefix}/batch-out/test\"\n",
    "\n",
    "transformer_val = xgb.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    output_path=batch_out_val\n",
    ")\n",
    "transformer_val.transform(\n",
    "    data=valX_s3_uri,\n",
    "    content_type=\"text/csv\",\n",
    "    split_type=\"Line\"\n",
    ")\n",
    "transformer_val.wait()\n",
    "\n",
    "transformer_test = xgb.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    output_path=batch_out_test\n",
    ")\n",
    "transformer_test.transform(\n",
    "    data=testX_s3_uri,\n",
    "    content_type=\"text/csv\",\n",
    "    split_type=\"Line\"\n",
    ")\n",
    "transformer_test.wait()\n",
    "\n",
    "print(\"Batch transform complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa40ecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: download first/only output file from the transform folder\n",
    "def download_single_output(s3_uri_folder, local_name):\n",
    "    files = S3Downloader.list(s3_uri_folder)\n",
    "    # Find the *.out file\n",
    "    out_files = [u for u in files if u.endswith(\".out\")]\n",
    "    assert out_files, f\"No .out files found under {s3_uri_folder}\"\n",
    "    S3Downloader.download(out_files[0], local_name)\n",
    "    return local_name\n",
    "\n",
    "val_pred_file  = download_single_output(batch_out_val,  \"val_preds.out\")\n",
    "test_pred_file = download_single_output(batch_out_test, \"test_preds.out\")\n",
    "\n",
    "# The built-in XGBoost returns one probability per line for binary:logistic\n",
    "val_proba  = pd.read_csv(val_pred_file,  header=None).iloc[:,0].astype(float).values\n",
    "test_proba = pd.read_csv(test_pred_file, header=None).iloc[:,0].astype(float).values\n",
    "\n",
    "# Join with meta for evaluation\n",
    "val_tbl  = val_meta.copy()\n",
    "val_tbl[\"proba\"] = val_proba\n",
    "\n",
    "test_tbl = test_meta.copy()\n",
    "test_tbl[\"proba\"] = test_proba\n",
    "\n",
    "# Pick cutoff on validation (prefer higher precision; tie-break on F1)\n",
    "best = None\n",
    "rows = []\n",
    "for thr in CUTOFF_GRID:\n",
    "    preds = (val_tbl[\"proba\"].values >= thr).astype(int)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(val_tbl[\"label\"].values, preds, average=\"binary\", zero_division=0)\n",
    "    rows.append((thr, p, r, f1))\n",
    "    if (best is None) or (p > best[1]) or (p == best[1] and f1 > best[3]):\n",
    "        best = (thr, p, r, f1)\n",
    "\n",
    "cutoff = float(best[0])\n",
    "print(\"Validation sweep (thr, P, R, F1):\")\n",
    "for r in rows:\n",
    "    print(\"  thr=%.2f  P=%.3f  R=%.3f  F1=%.3f\" % r)\n",
    "print(\"\\nChosen cutoff (prefers precision): %.2f  (P=%.3f, R=%.3f, F1=%.3f)\" %\n",
    "      (best[0], best[1], best[2], best[3]))\n",
    "\n",
    "# Persistence rule: require >= PERSIST_TICKS consecutive ticks with proba >= cutoff\n",
    "def apply_persistence(df_in, cutoff, persist_ticks):\n",
    "    df_in = df_in.sort_values(\"t\").reset_index(drop=True).copy()\n",
    "    df_in[\"pred_raw\"] = (df_in[\"proba\"] >= cutoff).astype(int)\n",
    "    roll = df_in[\"pred_raw\"].rolling(window=persist_ticks, min_periods=persist_ticks).sum()\n",
    "    df_in[\"pred_persist\"] = (roll >= persist_ticks).astype(int)\n",
    "    return df_in\n",
    "\n",
    "val_tbl  = apply_persistence(val_tbl,  cutoff, PERSIST_TICKS)\n",
    "test_tbl = apply_persistence(test_tbl, cutoff, PERSIST_TICKS)\n",
    "\n",
    "# Metrics (TEST)\n",
    "p, r, f1, _ = precision_recall_fscore_support(test_tbl[\"label\"], test_tbl[\"pred_persist\"],\n",
    "                                              average=\"binary\", zero_division=0)\n",
    "try:\n",
    "    auc_val  = roc_auc_score(val_tbl[\"label\"],  val_tbl[\"proba\"])\n",
    "    auc_test = roc_auc_score(test_tbl[\"label\"], test_tbl[\"proba\"])\n",
    "except Exception:\n",
    "    auc_val = auc_test = np.nan\n",
    "\n",
    "print(\"\\nTEST metrics with persistence:\")\n",
    "print(f\"  Precision={p:.3f}  Recall={r:.3f}  F1={f1:.3f}  (AUC Val={auc_val:.3f}, AUC Test={auc_test:.3f})\")\n",
    "\n",
    "# Show intervals when Trigger B is ON in TEST\n",
    "on = test_tbl.loc[test_tbl[\"pred_persist\"] == 1, \"t\"].to_numpy()\n",
    "if on.size == 0:\n",
    "    print(\"\\nNo Trigger B intervals on TEST with current cutoff/persistence.\")\n",
    "else:\n",
    "    # Find contiguous blocks\n",
    "    blocks = []\n",
    "    start = on[0]; prev = on[0]\n",
    "    for tt in on[1:]:\n",
    "        if tt - prev > tick + 1e-6:\n",
    "            blocks.append((start, prev))\n",
    "            start = tt\n",
    "        prev = tt\n",
    "    blocks.append((start, prev))\n",
    "    print(\"\\nTrigger B active intervals on TEST (t_start → t_end):\")\n",
    "    for a,b in blocks:\n",
    "        dur = b - a + tick\n",
    "        print(f\"  {a:.1f}s → {b:.1f}s   (~{dur:.1f}s)\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
