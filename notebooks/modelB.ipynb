{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae03fb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "CSV_PATH = r\"C:\\Hackathon\\gunshot\\modelB_predictors.csv\"   # input with columns: t, outward_fraction, mean_outward_speed_mps\n",
    "\n",
    "\n",
    "EVENT_START_S = 25202.5\n",
    "EVENT_END_S   = 25227.5\n",
    "\n",
    "TRAIN_FRAC = 0.70   # first 70% of time for train/tune\n",
    "VAL_FRAC   = 0.15   # next 15% for validation (threshold tuning)\n",
    "# last 15% becomes the test slice\n",
    "\n",
    "PERSIST_TICKS = 2   # require >= 2 consecutive ticks above the cutoff\n",
    "\n",
    "CUTOFF_GRID = np.linspace(0.50, 0.95, 10)  # candidate probability cutoffs to try on validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aee3898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time split:\n",
      "  Train: t <= 30237.5\n",
      "  Val:   30237.5 < t <= 36717.5\n",
      "  Test:  t > 36717.5\n",
      "Shapes: (12096, 2) (2592, 2) (2593, 2)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Basic sanity\n",
    "assert {\"t\",\"outward_fraction\",\"mean_outward_speed_mps\"}.issubset(df.columns), \\\n",
    "       \"CSV must contain t, outward_fraction, mean_outward_speed_mps\"\n",
    "\n",
    "# Label: 1 inside the event window, else 0\n",
    "df[\"label\"] = ((df[\"t\"] >= EVENT_START_S) & (df[\"t\"] <= EVENT_END_S)).astype(int)\n",
    "\n",
    "# Sort by time (very important for time-based split)\n",
    "df = df.sort_values(\"t\").reset_index(drop=True)\n",
    "\n",
    "# Work out the time-based indices for train / val / test\n",
    "unique_t = df[\"t\"].unique()\n",
    "nT = len(unique_t)\n",
    "t_train_end = unique_t[int(nT * TRAIN_FRAC) - 1]\n",
    "t_val_end   = unique_t[int(nT * (TRAIN_FRAC + VAL_FRAC)) - 1]\n",
    "\n",
    "# Split masks\n",
    "is_train = df[\"t\"] <= t_train_end\n",
    "is_val   = (df[\"t\"] > t_train_end) & (df[\"t\"] <= t_val_end)\n",
    "is_test  = df[\"t\"] > t_val_end\n",
    "\n",
    "print(\"Time split:\")\n",
    "print(f\"  Train: t <= {t_train_end}\")\n",
    "print(f\"  Val:   {t_train_end} < t <= {t_val_end}\")\n",
    "print(f\"  Test:  t > {t_val_end}\")\n",
    "\n",
    "# Build feature matrices (2 columns only) and labels\n",
    "FEATS = [\"outward_fraction\", \"mean_outward_speed_mps\"]\n",
    "\n",
    "X_train, y_train = df.loc[is_train, FEATS].values, df.loc[is_train, \"label\"].values\n",
    "X_val,   y_val   = df.loc[is_val,   FEATS].values, df.loc[is_val,   \"label\"].values\n",
    "X_test,  y_test  = df.loc[is_test,  FEATS].values, df.loc[is_test,  \"label\"].values\n",
    "\n",
    "print(\"Shapes:\", X_train.shape, X_val.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc2c96b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC: 0.999\n",
      "AUC calc skipped: Only one class present in y_true. ROC AUC score is not defined in that case.\n"
     ]
    }
   ],
   "source": [
    "# Handle class imbalance a bit (helps if evac frames are rare)\n",
    "pos = (y_train == 1).sum()\n",
    "neg = (y_train == 0).sum()\n",
    "scale_pos_weight = (neg / max(pos, 1)) if pos > 0 else 1.0\n",
    "\n",
    "clf = xgb.XGBClassifier(\n",
    "    n_estimators=60,         # small model\n",
    "    max_depth=2,            # very shallow trees\n",
    "    learning_rate=0.10,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    reg_lambda=1.0,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    n_jobs=-1,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Quick AUC check (optional)\n",
    "try:\n",
    "    print(\"Train AUC:\", roc_auc_score(y_train, clf.predict_proba(X_train)[:,1]).round(3))\n",
    "    print(\"Val   AUC:\", roc_auc_score(y_val,   clf.predict_proba(X_val)[:,1]).round(3))\n",
    "except Exception as e:\n",
    "    print(\"AUC calc skipped:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d36ca70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sweep (thr, precision, recall, f1):\n",
      "  thr=0.50  P=0.000  R=0.000  F1=0.000\n",
      "  thr=0.55  P=0.000  R=0.000  F1=0.000\n",
      "  thr=0.60  P=0.000  R=0.000  F1=0.000\n",
      "  thr=0.65  P=0.000  R=0.000  F1=0.000\n",
      "  thr=0.70  P=0.000  R=0.000  F1=0.000\n",
      "  thr=0.75  P=0.000  R=0.000  F1=0.000\n",
      "  thr=0.80  P=0.000  R=0.000  F1=0.000\n",
      "  thr=0.85  P=0.000  R=0.000  F1=0.000\n",
      "  thr=0.90  P=0.000  R=0.000  F1=0.000\n",
      "  thr=0.95  P=0.000  R=0.000  F1=0.000\n",
      "\n",
      "Chosen cutoff (prefers higher precision): 0.5\n",
      "Val metrics at cutoff →  P=0.000  R=0.000  F1=0.000\n"
     ]
    }
   ],
   "source": [
    "proba_val = clf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "best = None\n",
    "rows = []\n",
    "for thr in CUTOFF_GRID:\n",
    "    preds = (proba_val >= thr).astype(int)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(y_val, preds, average=\"binary\", zero_division=0)\n",
    "    rows.append((thr, p, r, f1))\n",
    "    if (best is None) or (p > best[1]) or (p == best[1] and f1 > best[3]):  # prefer precision, break ties by F1\n",
    "        best = (thr, p, r, f1)\n",
    "\n",
    "cutoff = float(best[0])\n",
    "val_precision, val_recall, val_f1 = best[1], best[2], best[3]\n",
    "\n",
    "print(\"Validation sweep (thr, precision, recall, f1):\")\n",
    "for r in rows:\n",
    "    print(\"  thr=%.2f  P=%.3f  R=%.3f  F1=%.3f\" % r)\n",
    "\n",
    "print(\"\\nChosen cutoff (prefers higher precision):\", cutoff)\n",
    "print(\"Val metrics at cutoff →  P=%.3f  R=%.3f  F1=%.3f\" % (val_precision, val_recall, val_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9554978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST metrics with persistence (P,R,F1): 0.0 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "# Get predicted probabilities for the full df (so we can report by time)\n",
    "df[\"proba\"] = clf.predict_proba(df[FEATS].values)[:, 1]\n",
    "\n",
    "# Determine the typical tick size (seconds) from the data\n",
    "tick = df[\"t\"].diff().dropna().mode().iloc[0] if df[\"t\"].nunique() > 1 else 2.5\n",
    "\n",
    "# Base decision per frame (before persistence)\n",
    "df[\"pred_raw\"] = (df[\"proba\"] >= cutoff).astype(int)\n",
    "\n",
    "# Apply persistence ONLY within each split (train/val/test) to keep evaluation clean\n",
    "def apply_persistence(sub):\n",
    "    sub = sub.sort_values(\"t\").copy()\n",
    "    roll = sub[\"pred_raw\"].rolling(window=PERSIST_TICKS, min_periods=PERSIST_TICKS).sum()\n",
    "    sub[\"pred_persist\"] = (roll >= PERSIST_TICKS).astype(int)\n",
    "    return sub\n",
    "\n",
    "df.loc[is_train, \"pred_persist\"] = apply_persistence(df.loc[is_train]).loc[is_train, \"pred_persist\"]\n",
    "df.loc[is_val,   \"pred_persist\"] = apply_persistence(df.loc[is_val]).loc[is_val,   \"pred_persist\"]\n",
    "df.loc[is_test,  \"pred_persist\"] = apply_persistence(df.loc[is_test]).loc[is_test,  \"pred_persist\"]\n",
    "\n",
    "# Test metrics\n",
    "test = df.loc[is_test].sort_values(\"t\")\n",
    "p, r, f1, _ = precision_recall_fscore_support(test[\"label\"].values,\n",
    "                                              test[\"pred_persist\"].values,\n",
    "                                              average=\"binary\",\n",
    "                                              zero_division=0)\n",
    "print(\"\\nTEST metrics with persistence (P,R,F1):\", round(p,3), round(r,3), round(f1,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a3fa62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Trigger B intervals on TEST with current cutoff & persistence.\n"
     ]
    }
   ],
   "source": [
    "test = test.reset_index(drop=True)\n",
    "on = test.loc[test[\"pred_persist\"] == 1, \"t\"].to_numpy()\n",
    "\n",
    "if on.size == 0:\n",
    "    print(\"No Trigger B intervals on TEST with current cutoff & persistence.\")\n",
    "else:\n",
    "    blocks = []\n",
    "    start = on[0]; prev = on[0]\n",
    "    for tt in on[1:]:\n",
    "        if tt - prev > tick + 1e-6:       # gap → close the block\n",
    "            blocks.append((start, prev))\n",
    "            start = tt\n",
    "        prev = tt\n",
    "    blocks.append((start, prev))\n",
    "    print(\"Trigger B active intervals on TEST (t_start → t_end):\")\n",
    "    for a,b in blocks:\n",
    "        dur = b - a + tick\n",
    "        print(f\"  {a:.1f}s → {b:.1f}s   (~{dur:.1f}s)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86b76f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: modelB_classifier_outputs.csv  with 17281 rows\n",
      "Columns: ['t', 'outward_fraction', 'mean_outward_speed_mps', 'label', 'proba', 'pred_raw', 'pred_persist']\n",
      "\n",
      "Tip: Use 'pred_persist' as Trigger B when fusing with Trigger A (A AND B within 3–5s).\n"
     ]
    }
   ],
   "source": [
    "# Per-frame classifier outputs (full day)\n",
    "out_cols = [\"t\", \"outward_fraction\", \"mean_outward_speed_mps\", \"label\", \"proba\", \"pred_raw\", \"pred_persist\"]\n",
    "df[out_cols].to_csv(r\"C:\\Hackathon\\gunshot\\modelB_classifier_outputs.csv\", index=False)\n",
    "\n",
    "print(\"\\nSaved: modelB_classifier_outputs.csv  with\", df.shape[0], \"rows\")\n",
    "print(\"Columns:\", out_cols)\n",
    "print(\"\\nTip: Use 'pred_persist' as Trigger B when fusing with Trigger A (A AND B within 3–5s).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "924b720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "# ---- Small knobs you can tune (must match your earlier choices) ----\n",
    "EVENT_START_S = 25202.5\n",
    "EVENT_END_S   = 25227.5\n",
    "\n",
    "TRAIN_FRAC = 0.70   # first 70% of time → train\n",
    "VAL_FRAC   = 0.15   # next 15% → validation (choose cutoff here)\n",
    "PERSIST_TICKS = 2   # require >= 2 consecutive ticks above cutoff\n",
    "\n",
    "CUTOFF_GRID = np.linspace(0.50, 0.95, 10)  # thresholds to try on validation\n",
    "FEATS = [\"outward_fraction\", \"mean_outward_speed_mps\"]  # only two features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42fdecda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time split:\n",
      "  Train: t <= 30237.5\n",
      "  Val:   30237.5 < t <= 36717.5\n",
      "  Test:  t > 36717.5\n"
     ]
    }
   ],
   "source": [
    "# Load the predictors you already built locally (no SageMaker needed)\n",
    "df = pd.read_csv(r\"C:\\Hackathon\\gunshot\\modelB_predictors.csv\")\n",
    "assert set([\"t\"]+FEATS).issubset(df.columns), \"modelB_predictors.csv missing required columns.\"\n",
    "\n",
    "# Label = 1 inside the event window, else 0 (used only for validation/testing metrics)\n",
    "df = df.sort_values(\"t\").reset_index(drop=True)\n",
    "df[\"label\"] = ((df[\"t\"] >= EVENT_START_S) & (df[\"t\"] <= EVENT_END_S)).astype(int)\n",
    "\n",
    "# Time-based split (prevents leakage)\n",
    "unique_t = df[\"t\"].unique()\n",
    "t_train_end = unique_t[int(len(unique_t)*TRAIN_FRAC) - 1]\n",
    "t_val_end   = unique_t[int(len(unique_t)*(TRAIN_FRAC+VAL_FRAC)) - 1]\n",
    "\n",
    "is_train = df[\"t\"] <= t_train_end\n",
    "is_val   = (df[\"t\"] > t_train_end) & (df[\"t\"] <= t_val_end)\n",
    "is_test  = df[\"t\"] > t_val_end\n",
    "\n",
    "# Detect the typical tick spacing (seconds), used later when summarizing intervals\n",
    "tick = df[\"t\"].diff().dropna().mode().iloc[0] if df[\"t\"].nunique() > 1 else 2.5\n",
    "\n",
    "print(\"Time split:\")\n",
    "print(f\"  Train: t <= {t_train_end}\")\n",
    "print(f\"  Val:   {t_train_end} < t <= {t_val_end}\")\n",
    "print(f\"  Test:  t > {t_val_end}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f58b69e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used in-memory classifier `clf` to get probabilities.\n"
     ]
    }
   ],
   "source": [
    "proba_all = None\n",
    "\n",
    "# Case 1: Use an in-memory model called `clf` if it exists (from your modelB.ipynb workflow)\n",
    "if \"clf\" in globals():\n",
    "    try:\n",
    "        proba_all = clf.predict_proba(df[FEATS].values)[:, 1]\n",
    "        print(\"Used in-memory classifier `clf` to get probabilities.\")\n",
    "    except Exception as e:\n",
    "        print(\"Found `clf` but couldn't use predict_proba:\", e)\n",
    "\n",
    "# Case 2: Try to load a saved local model (JSON from xgboost Booster or a joblib/sklearn pickle)\n",
    "if proba_all is None:\n",
    "    import os\n",
    "    try:\n",
    "        if os.path.exists(\"modelB_xgb.json\"):\n",
    "            booster = xgb.Booster()\n",
    "            booster.load_model(\"modelB_xgb.json\")\n",
    "            dmat = xgb.DMatrix(df[FEATS].values)\n",
    "            proba_all = booster.predict(dmat)\n",
    "            print(\"Loaded probabilities from modelB_xgb.json (XGBoost Booster).\")\n",
    "        elif os.path.exists(\"modelB_xgb.pkl\"):\n",
    "            import joblib\n",
    "            clf = joblib.load(\"modelB_xgb.pkl\")\n",
    "            proba_all = clf.predict_proba(df[FEATS].values)[:, 1]\n",
    "            print(\"Loaded probabilities from modelB_xgb.pkl (sklearn-style model).\")\n",
    "    except Exception as e:\n",
    "        print(\"Tried to load a saved model but failed:\", e)\n",
    "\n",
    "# Case 3: Tiny fallback training here (quick MVP)\n",
    "if proba_all is None:\n",
    "    print(\"Training a tiny fallback XGBoost model locally (MVP).\")\n",
    "    from xgboost import XGBClassifier\n",
    "    X_tr, y_tr = df.loc[is_train, FEATS].values, df.loc[is_train, \"label\"].values\n",
    "    pos = (y_tr == 1).sum()\n",
    "    neg = (y_tr == 0).sum()\n",
    "    spw = (neg / max(pos, 1)) if pos > 0 else 1.0  # handle imbalance a bit\n",
    "\n",
    "    clf = XGBClassifier(\n",
    "        n_estimators=80,\n",
    "        max_depth=2,\n",
    "        learning_rate=0.10,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        reg_lambda=1.0,\n",
    "        objective=\"binary:logistic\",\n",
    "        n_jobs=-1,\n",
    "        scale_pos_weight=spw,\n",
    "        random_state=42\n",
    "    )\n",
    "    clf.fit(X_tr, y_tr)\n",
    "    proba_all = clf.predict_proba(df[FEATS].values)[:, 1]\n",
    "\n",
    "# Attach probabilities to the full table\n",
    "df[\"proba\"] = proba_all\n",
    "\n",
    "# Quick sanity: AUCs (optional)\n",
    "try:\n",
    "    auc_tr  = roc_auc_score(df.loc[is_train, \"label\"], df.loc[is_train, \"proba\"])\n",
    "    auc_val = roc_auc_score(df.loc[is_val,   \"label\"], df.loc[is_val,   \"proba\"])\n",
    "    print(f\"AUC Train={auc_tr:.3f}  AUC Val={auc_val:.3f}\")\n",
    "except Exception:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b2b44f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved modelB_classifier_outputs_sagemaker.csv with columns: ['t', 'label', 'proba', 'pred_raw', 'pred_persist']\n"
     ]
    }
   ],
   "source": [
    "# 1) Pick a cutoff on the validation slice (prefer higher precision, tie-break by F1)\n",
    "val_tbl = df.loc[is_val, [\"t\",\"label\",\"proba\"]].reset_index(drop=True)\n",
    "best = None\n",
    "for thr in CUTOFF_GRID:\n",
    "    preds = (val_tbl[\"proba\"].values >= thr).astype(int)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(val_tbl[\"label\"].values, preds,\n",
    "                                                  average=\"binary\", zero_division=0)\n",
    "    if (best is None) or (p > best[1]) or (p == best[1] and f1 > best[3]):\n",
    "        best = (float(thr), float(p), float(r), float(f1))\n",
    "cutoff = best[0]\n",
    "\n",
    "# 2) Persistence: require >= PERSIST_TICKS consecutive ticks above cutoff\n",
    "def add_persistence(sub_df, cutoff, persist_ticks):\n",
    "    sub_df = sub_df.sort_values(\"t\").reset_index(drop=True).copy()\n",
    "    sub_df[\"pred_raw\"] = (sub_df[\"proba\"] >= cutoff).astype(int)\n",
    "    roll = sub_df[\"pred_raw\"].rolling(window=persist_ticks, min_periods=persist_ticks).sum()\n",
    "    sub_df[\"pred_persist\"] = (roll >= persist_ticks).astype(int)\n",
    "    return sub_df\n",
    "\n",
    "df_out = add_persistence(df[[\"t\",\"label\",\"proba\"]], cutoff, PERSIST_TICKS)\n",
    "\n",
    "# 3) Save the exact file your fusion script looks for\n",
    "df_out.to_csv(r\"C:\\Hackathon\\gunshot\\modelB_classifier_outputs.csv\", index=False)\n",
    "print(\"Saved modelB_classifier_outputs_sagemaker.csv with columns:\", list(df_out.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e221ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc80",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
