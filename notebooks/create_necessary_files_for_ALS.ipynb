{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc994c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using input CSV: C:\\Hackathon\\gunshot\\gunshot_case1_sim.csv\n"
     ]
    }
   ],
   "source": [
    "import os, json, math\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "INPUT_CSV = r\"C:\\Hackathon\\gunshot\\gunshot_anomaly.csv\"\n",
    "print(\"Using input CSV:\", INPUT_CSV)\n",
    "\n",
    "# Output folders\n",
    "OUT_DIR = Path(\"out\")\n",
    "FRAMES_DIR = OUT_DIR / \"frames\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FRAMES_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95c8fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded columns: ['phone_id', 't', 'lat', 'lon']\n",
      "Dropped 0 rows with invalid t/lat/lon\n",
      "          phone_id    t        lat         lon\n",
      "0  356000000000000  0.0  38.540894 -121.749281\n",
      "1  356000000000018  0.0  38.540984 -121.749490\n",
      "2  356000000000026  0.0  38.541188 -121.749226\n",
      "3  356000000000034  0.0  38.540922 -121.749136\n",
      "4  356000000000042  0.0  38.540896 -121.749406\n",
      "Rows: 1100 Devices: 100 Unique times: 11\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "print(\"Loaded columns:\", list(df.columns))\n",
    "\n",
    "lower_map = {c.lower(): c for c in df.columns}\n",
    "\n",
    "def col(name_candidates):\n",
    "    for cand in name_candidates:\n",
    "        if cand in lower_map:\n",
    "            return lower_map[cand]\n",
    "    return None\n",
    "\n",
    "# Accept either the new names or the old ones and convert to the new standard names\n",
    "phone_col = col([\"phone_id\", \"imei\"])\n",
    "time_col  = col([\"t\", \"timestamp\"])\n",
    "lat_col   = col([\"lat\"])\n",
    "lon_col   = col([\"lon\", \"lng\", \"long\"])\n",
    "\n",
    "required_missing = [n for n,v in {\n",
    "    \"phone_id/imei\": phone_col,\n",
    "    \"t/timestamp\": time_col,\n",
    "    \"lat\": lat_col,\n",
    "    \"lon/lng\": lon_col\n",
    "}.items() if v is None]\n",
    "\n",
    "if required_missing:\n",
    "    raise ValueError(f\"Missing required columns in CSV: {required_missing}\")\n",
    "\n",
    "# Rename to standard names we will use everywhere\n",
    "df = df.rename(columns={\n",
    "    phone_col: \"phone_id\",\n",
    "    time_col:  \"t\",\n",
    "    lat_col:   \"lat\",\n",
    "    lon_col:   \"lon\"\n",
    "})\n",
    "\n",
    "# Keep only what we need (and in the right order)\n",
    "df = df[[\"phone_id\", \"t\", \"lat\", \"lon\"]]\n",
    "\n",
    "# Coerce types (very important for mapping)\n",
    "df[\"phone_id\"] = df[\"phone_id\"].astype(str)\n",
    "df[\"t\"] = pd.to_numeric(df[\"t\"], errors=\"coerce\")\n",
    "df[\"lat\"] = pd.to_numeric(df[\"lat\"], errors=\"coerce\")\n",
    "df[\"lon\"] = pd.to_numeric(df[\"lon\"], errors=\"coerce\")\n",
    "\n",
    "# Drop rows that failed to parse\n",
    "before = len(df)\n",
    "df = df.dropna(subset=[\"t\", \"lat\", \"lon\"])\n",
    "after = len(df)\n",
    "print(f\"Dropped {before - after} rows with invalid t/lat/lon\")\n",
    "\n",
    "# Basic WGS84 range checks\n",
    "bad_lat = ~df[\"lat\"].between(-90, 90)\n",
    "bad_lon = ~df[\"lon\"].between(-180, 180)\n",
    "bad = df[bad_lat | bad_lon]\n",
    "if len(bad):\n",
    "    print(\"WARNING: Found rows outside lat/lon range; dropping:\", len(bad))\n",
    "    df = df[~(bad_lat | bad_lon)]\n",
    "\n",
    "# Sort and reset index\n",
    "df = df.sort_values([\"t\", \"phone_id\"]).reset_index(drop=True)\n",
    "print(df.head())\n",
    "print(\"Rows:\", len(df), \"Devices:\", df[\"phone_id\"].nunique(), \"Unique times:\", df[\"t\"].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4866e0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped duplicate rows: 0\n",
      "Per-time summary (first 10 rows):\n",
      "      t  n_points  n_devices\n",
      "0   0.0       100        100\n",
      "1   2.5       100        100\n",
      "2   5.0       100        100\n",
      "3   7.5       100        100\n",
      "4  10.0       100        100\n",
      "5  12.5       100        100\n",
      "6  15.0       100        100\n",
      "7  17.5       100        100\n",
      "8  20.0       100        100\n",
      "9  22.5       100        100\n"
     ]
    }
   ],
   "source": [
    "# Remove exact duplicates if any\n",
    "before = len(df)\n",
    "df = df.drop_duplicates(subset=[\"phone_id\", \"t\", \"lat\", \"lon\"])\n",
    "print(\"Dropped duplicate rows:\", before - len(df))\n",
    "\n",
    "# Optional: round lat/lon to 6 decimals (~0.11 m) — nice balance of precision vs. filesize\n",
    "df[\"lat\"] = df[\"lat\"].round(6)\n",
    "df[\"lon\"] = df[\"lon\"].round(6)\n",
    "\n",
    "# Summary by time (helps you check expectations)\n",
    "summary = df.groupby(\"t\").agg(\n",
    "    n_points=(\"phone_id\", \"count\"),\n",
    "    n_devices=(\"phone_id\", \"nunique\")\n",
    ").reset_index()\n",
    "print(\"Per-time summary (first 10 rows):\")\n",
    "print(summary.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525e0ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map center (lat, lon): (38.541094, -121.749366)\n",
      "BBox lat: [38.540548, 38.541553]  lon: [-121.750067, -121.748593]\n",
      "Approx extent: width ≈ 128.5 m, height ≈ 111.6 m\n",
      "Suggested default zoom for a 900px map: z ≈ 19.7\n"
     ]
    }
   ],
   "source": [
    "def meters_per_degree(lat_deg: float):\n",
    "    lat = math.radians(lat_deg)\n",
    "    m_per_deg_lat = 111132.92 - 559.82*math.cos(2*lat) + 1.175*math.cos(4*lat) - 0.0023*math.cos(6*lat)\n",
    "    m_per_deg_lon = 111412.84*math.cos(lat) - 93.5*math.cos(3*lat) + 0.118*math.cos(5*lat)\n",
    "    return m_per_deg_lat, m_per_deg_lon\n",
    "\n",
    "lat_min, lat_max = df[\"lat\"].min(), df[\"lat\"].max()\n",
    "lon_min, lon_max = df[\"lon\"].min(), df[\"lon\"].max()\n",
    "\n",
    "lat_ctr = float(df[\"lat\"].median())\n",
    "lon_ctr = float(df[\"lon\"].median())\n",
    "\n",
    "m_per_deg_lat, m_per_deg_lon = meters_per_degree(lat_ctr)\n",
    "\n",
    "width_m  = (lon_max - lon_min) * m_per_deg_lon\n",
    "height_m = (lat_max - lat_min) * m_per_deg_lat\n",
    "\n",
    "print(f\"Map center (lat, lon): ({lat_ctr:.6f}, {lon_ctr:.6f})\")\n",
    "print(f\"BBox lat: [{lat_min:.6f}, {lat_max:.6f}]  lon: [{lon_min:.6f}, {lon_max:.6f}]\")\n",
    "print(f\"Approx extent: width ≈ {width_m:.1f} m, height ≈ {height_m:.1f} m\")\n",
    "\n",
    "# Recommend a zoom for a ~900 px wide map: meters per pixel at zoom z ~ 156543.03392 * cos(lat) / 2^z\n",
    "def recommend_zoom(width_m, lat_deg, pixels=900):\n",
    "    if width_m <= 0:\n",
    "        return 18\n",
    "    m_per_px_needed = width_m / pixels\n",
    "    m_per_px_z0_at_lat = 156543.03392 * math.cos(math.radians(lat_deg))\n",
    "    z = math.log2(m_per_px_z0_at_lat / m_per_px_needed)\n",
    "    return max(1, min(22, round(z, 1)))\n",
    "\n",
    "zoom_guess = recommend_zoom(max(width_m, height_m), lat_ctr, pixels=900)\n",
    "print(f\"Suggested default zoom for a 900px map: z ≈ {zoom_guess}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f14673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned CSV: C:\\Hackathon\\gunshot\\out\\gunshot_clean.csv\n"
     ]
    }
   ],
   "source": [
    "clean_csv_path = OUT_DIR / \"gunshot_clean.csv\"\n",
    "df[[\"phone_id\", \"t\", \"lat\", \"lon\"]].to_csv(clean_csv_path, index=False)\n",
    "print(\"Saved cleaned CSV:\", clean_csv_path.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1230876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all-points GeoJSON: C:\\Hackathon\\gunshot\\out\\gunshot_points_all.geojson (features: 1100 )\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "for r in df.itertuples(index=False):\n",
    "    feat = {\n",
    "        \"type\": \"Feature\",\n",
    "        \"geometry\": {\"type\": \"Point\", \"coordinates\": [float(r.lon), float(r.lat)]},\n",
    "        \"properties\": {\"phone_id\": str(r.phone_id), \"t\": float(r.t)}\n",
    "    }\n",
    "    features.append(feat)\n",
    "\n",
    "geojson_all = {\"type\": \"FeatureCollection\", \"features\": features}\n",
    "\n",
    "all_path = OUT_DIR / \"gunshot_points_all.geojson\"\n",
    "with open(all_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(geojson_all, f, ensure_ascii=False, separators=(\",\", \":\"))\n",
    "print(\"Saved all-points GeoJSON:\", all_path.resolve(), \"(features:\", len(features), \")\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9511d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique timestamps: [0.0, 2.5, 5.0, 7.5, 10.0] ... total: 11\n",
      "Wrote 11 frame files to: C:\\Hackathon\\gunshot\\out\\frames\n",
      "Frame index: C:\\Hackathon\\gunshot\\out\\frames_index.json\n"
     ]
    }
   ],
   "source": [
    "times = sorted(df[\"t\"].unique().tolist())\n",
    "print(\"Unique timestamps:\", times[:5], \"... total:\", len(times))\n",
    "\n",
    "index_rows = []\n",
    "for idx, tval in enumerate(times):\n",
    "    df_t = df[df[\"t\"] == tval]\n",
    "    feats = []\n",
    "    for r in df_t.itertuples(index=False):\n",
    "        feats.append({\n",
    "            \"type\": \"Feature\",\n",
    "            \"geometry\": {\"type\": \"Point\", \"coordinates\": [float(r.lon), float(r.lat)]},\n",
    "            \"properties\": {\"phone_id\": str(r.phone_id), \"t\": float(r.t)}\n",
    "        })\n",
    "    frame = {\"type\": \"FeatureCollection\", \"features\": feats}\n",
    "    frame_name = f\"frame_{idx:03d}.geojson\"\n",
    "    frame_path = FRAMES_DIR / frame_name\n",
    "    with open(frame_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(frame, f, ensure_ascii=False, separators=(\",\", \":\"))\n",
    "    index_rows.append({\"index\": idx, \"t\": float(tval), \"file\": str(frame_path.name)})\n",
    "\n",
    "# Write a tiny index so your web app can load frames easily\n",
    "with open(OUT_DIR / \"frames_index.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(index_rows, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Wrote {len(times)} frame files to:\", FRAMES_DIR.resolve())\n",
    "print(\"Frame index:\", (OUT_DIR / \"frames_index.json\").resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15051e93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc80",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
